import asyncio
import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv

# Load environment
load_dotenv()

st.set_page_config(page_title="SFPL 2025 Wrap-up", page_icon="ðŸ“š", layout="centered")

st.title("SF Public Library 2025 Wrap-up")
st.caption("Displaying previously scraped data from library_app.py")

# Load artifacts saved by library_app.py
books_path = os.path.join(os.getcwd(), "books_2025.csv")
wrapup_path = os.path.join(os.getcwd(), "wrapup_2025.txt")

st.subheader("Books from 2025")
if os.path.exists(books_path):
	try:
		df = pd.read_csv(books_path)
		# Ensure only title/author columns
		cols = [c for c in ["title", "author"] if c in df.columns]
		df = df[cols] if cols else df
		st.dataframe(df)
	except Exception as e:
		st.error(f"Failed to read books_2025.csv: {e}")
else:
	st.info("books_2025.csv not found. Run library_app.py to generate it.")

st.subheader("Wrap-up")
if os.path.exists(wrapup_path):
	try:
		with open(wrapup_path, "r") as f:
			content = f.read()
		st.markdown(content)
	except Exception as e:
		st.error(f"Failed to read wrapup_2025.txt: {e}")
else:
	st.info("wrapup_2025.txt not found. Run library_app.py to generate it.")

st.divider()
st.caption("Artifacts are loaded from books_2025.csv and wrapup_2025.txt generated by library_app.py.")